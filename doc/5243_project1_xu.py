# -*- coding: utf-8 -*-
"""5243 Project1 - Xu.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VIy66nzav6Wh_OlccaMtal6ZtLcnIOn9

# STAT5342 Project 1
__Author:__ Mingze Xu<br>
__UNI:__ mx2269<br>
__Date:__ 7.8.2023<br>

## Introduction:

__What is philosophy?__ <br>
This is a really abstract question, and for most of us, we might not be able to give a proper definition to it. The origin of the term 'philosophy' can be traced back to ancient Greece, around the 6th century BCE. Some people might argue that philosophy is a branch of knowledge that seeks to understand the world and our place in it. This argument is really convincing. <br>
In this __History of Philosophy__ project, particularly the dataset __philosophy_data__, 36 world reknowned philosophers from 13 different schools of philosophy and their thounsands of sentences are included. From the dataset, we would manipulate the data and might be able to explore the progress or the development of the subject Philosophy. <br>
More specifically in this project, after researching the history of philosophy and simply oberserving the data, I would focus on how philosophy might have evolved. I categorized these schools into three groups: <br>
-  Ancient Greek Philosophy:Stoicism, Aristotle, Plato <br>
-  19th and 20th Century Philosophy: Capitalism, Continental, Feminism, German Idealism, Phenomenology, Communism, Nietzsche <br>
- Modern Philosophy: Analytic, Rationalism, Empiricism <br>

Acient Greek Philosophy and Modern Philosophy are actualy on the two endpoints of this situation, so I will focus on these two groups. <br>
__Research question__:
The research question would be how modern philosophy is different from the Ancient Greek Philosophy, from the aspects of writing language and the central theme.<br>
__Hypothesis__:
Considering the time gap of almost 2700 years, I hypothesize that the writing language would be different because the way people talk and write are evolving. Also, the central themes were also shifted because the ideology and understanding of life are changing in an unpredictable speed.

## Setup
"""

from google.colab import drive
drive.mount('/content/drive')

"""### importing the packages"""

# All packages used in this project are imported in this cell
import numpy as np 
import pandas as pd 
import matplotlib.pyplot as plt
import seaborn as sns
import re
import ast
import nltk
from nltk.corpus import stopwords
from wordcloud import WordCloud
import matplotlib.pyplot as plt
from nltk.probability import FreqDist

"""### importing the Dataset and printing the first five rows """

# The dataset is imported
philosophy_data = pd.read_csv('philosophy_data.csv')

# The first five rows are printed to show an insight into the dataset
philosophy_data.head(5)

"""## Data Cleaning and Data Wrangling"""

# The number of distinct authors and their name
author = philosophy_data['author'].unique()

# The number of distinct schools and their name
school = philosophy_data['school'].unique()

print(len(author), author)
print(len(school), school)

# Create dataframe 'schools' sorted the author by their schools
schools = philosophy_data.groupby('school')['author'].agg(lambda x: list(set(x)))
schools = schools.reset_index()
schools.columns = ['school', 'name']
schools['number of philosopher'] = schools['name'].apply(lambda x: len(x))
schools = schools.sort_values(by='number of philosopher', ascending=False)
schools

# Ignoring the possible space at the beginning of the sentence 
philosophy_data['sentence_str'] = philosophy_data['sentence_str'].str.strip()

# Create a new column 'sentence_split' storing the list of strings that are the words in the sentence
philosophy_data['sentence_split'] = philosophy_data['sentence_str'].str.split(r"[\s']+")

# Create a new column 'word_count' storing the number of words in the sentence
philosophy_data['word_count'] = philosophy_data['sentence_split'].str.len()

# Dataframe 'author_sentence_length' shows the average length of the sentences of each author
author_sentence_length = philosophy_data.groupby('author')['sentence_length'].mean().sort_values(ascending=False).to_frame()
author_sentence_length

# Dataframe 'author_word_count' shows the average number of words in the sentences of each author
author_word_count = philosophy_data.groupby('author')['word_count'].mean().sort_values(ascending=False).to_frame()
author_word_count

# Analytic
analytics = philosophy_data[philosophy_data['school'] == 'analytic']

# Rationalism
rationalisms = philosophy_data[philosophy_data['school'] == 'rationalism']

# Empiricism 
empiricisms = philosophy_data[philosophy_data['school'] == 'empiricism']

# Modern
modern = pd.concat([analytics, rationalisms, empiricisms], axis=0)
modern.head()

# Stoicism
stoicisms = philosophy_data[philosophy_data['school'] == 'stoicism']

# Aristotle
aristotles = philosophy_data[philosophy_data['school'] == 'aristotle']

# Plato
platos = philosophy_data[philosophy_data['school'] == 'plato']

# Ancient Greek
ancientgreek = pd.concat([stoicisms, aristotles, platos], axis=0)
ancientgreek.head()

"""### Summary of data cleaning and wrangling

1. Create dataframe __schools__ sorted the author by their schools 
2. Created column __word_count__ storing the number of words in the sentence
3. Created column __sentence_split__, which splits the sentence with __space__ and __single quotation mark__, because __'s__ standing for __is__ should also be considered as a word
4. In the original dataset, there is a column called __sentence_length__. This variable stores the number of chracters in the sentence. However, in my opnion, this is not really informative, because the length of a sentence should be the number of words in it. As a result, I calculated the average number of words in the sentence for each author
5. There are some new sub-dataframes created
5. The first three rows of the modified dataframe __philosophy_data__ will be printed below to provide an insight
"""

# The original data 'philosophy' is manipulated in many ways.
# So this cell prints out the new version of the dataframe which has a few more new columns
philosophy_data.head(3)

"""## Exploratory Data Analysis"""

# Use the explode method to convert each list of strings into multiple rows
modern_exploded = modern['sentence_split'].apply(pd.Series).stack().reset_index(level=1, drop=True)

# Get the frequency of each string in the exploded column
modern_freq = modern_exploded.value_counts().sort_values(ascending=False)


# Use the explode method to convert each list of strings into multiple rows
ancientgreek_exploded = ancientgreek['sentence_split'].apply(pd.Series).stack().reset_index(level=1, drop=True)

# Get the frequency of each string in the exploded column
ancientgreek_freq = ancientgreek_exploded.value_counts().sort_values(ascending=False)

print('modern_freq:', + modern_freq)

print('ancientgreek_freq:', + ancientgreek_freq)

# commonly used preposition - place
place_preposition = ['in', 'at', 'on', 'by', 'next to', 'beside', 'under', 'below', 'over', 'above', 'across', 'through', 'to', 'into', 'towards', 'onto', 'from', 'of']

# commonly used preposition - time
time_preposition = ['on', 'in', 'at', 'since', 'for', 'ago', 'before', 'to', 'past', 'till', 'untill', 'by']

# Calculating the frequencies of the place preposition and the place preposition
modern_place_frequency = 0
for index, row in modern.iterrows():
    for word in row['sentence_split']:
        if word in place_preposition:
            modern_place_frequency += 1

modern_time_frequency = 0
for index, row in modern.iterrows():
    for word in row['sentence_split']:
        if word in time_preposition:
            modern_time_frequency += 1

ancient_place_frequency = 0
for index, row in ancientgreek.iterrows():
    for word in row['sentence_split']:
        if word in place_preposition:
            ancient_place_frequency += 1

ancient_time_frequency = 0
for index, row in ancientgreek.iterrows():
    for word in row['sentence_split']:
        if word in time_preposition:
            ancient_time_frequency += 1

print('total words in modern:', modern_freq.sum())
print('modern_place_frequency:', modern_place_frequency)
print('modern_time_frequency:', modern_time_frequency)

print('total words in ancient greek:', ancientgreek_freq.sum())
print('ancient_place_frequency:', ancient_place_frequency)
print('ancient_time_frequency:', ancient_time_frequency)

# Plot of the preposition in both Acient Greek and Modern Philosophy

modern_data = [modern_freq.sum(), modern_place_frequency, modern_time_frequency]

ancient_data = [ancientgreek_freq.sum(), ancient_place_frequency, ancient_time_frequency]

# Bar chart data
x = range(len(modern_data))

fig, ax = plt.subplots()
bar_width = 0.35

bar1 = ax.bar(x, modern_data, bar_width, label='modern data')
bar2 = ax.bar([i + bar_width for i in x], ancient_data, bar_width, label='ancient data')

# Add labels and title
ax.set_xlabel('Variables')
ax.set_ylabel('Values')
ax.set_title('Comparison of Two Sets of Data')

# Add X-axis labels
ax.set_xticks([i + bar_width/2 for i in x])
ax.set_xticklabels(['modern_freq.sum', 'modern_place_frequency', 'modern_time_frequency'])

plt.legend()
plt.show()

# modern_stop = modern_freq[1:150].index.tolist()
# ancient_stop = ancientgreek_freq[1:150].index.tolist()
nltk.download('stopwords')
nltk.download('all')

# The stop_words that would be removed
stop_words = set(stopwords.words("english"))
stop_words_ob = {'one', 'thing', 'good', 'others', 'would'}
stop_words = stop_words | stop_words_ob

# Define two functions

# This function removes the stop words from the data
def remove_stop_words(text):
    words = nltk.word_tokenize(text)
    words = [word for word in words if word.lower() not in stop_words]
    return " ".join(words)

# This function removes the words that appear with low frequency
def remove_low_frequency_words(text):
    words = nltk.word_tokenize(text)
    fdist = FreqDist(words)
    words = [word for word in words if fdist[word] >= 2]
    return " ".join(words)

# Apply the functions defined to both sub-dataframe so that the plot would not be a mess
modern['nostop'] = modern['sentence_lowered'].apply(remove_stop_words).apply(remove_low_frequency_words)
ancientgreek['nostop'] = ancientgreek['sentence_lowered'].apply(remove_stop_words).apply(remove_low_frequency_words)

# Word Cloud for mordern data

# concatenate the list of words in the column
text = " ".join(str(word) for word in modern["nostop"])

# create a word cloud object
wordcloud = WordCloud(width = 800, height = 800, 
                background_color ='white', 
                stopwords = set(stop_words), 
                min_font_size = 10).generate(text)

# plot the word cloud
plt.figure(figsize = (4, 4), facecolor = None) 
plt.imshow(wordcloud) 
plt.axis("off") 
plt.tight_layout(pad = 0) 
  
plt.show()

# concatenate the list of words in the column
text = " ".join(str(word) for word in ancientgreek["nostop"])

# create a word cloud object
wordcloud = WordCloud(width = 800, height = 800, 
                background_color ='white', 
                stopwords = set(stop_words), 
                min_font_size = 10).generate(text)

# plot the word cloud
plt.figure(figsize = (4, 4), facecolor = None) 
plt.imshow(wordcloud) 
plt.axis("off") 
plt.tight_layout(pad = 0) 
  
plt.show()

"""## Summary of the entire project

### Procedures

1. At the very beginning of the project, even before data cleaning, I observed the entire dataset, and looked for the similarities and differences among the variables. So I acquired the relationship between the __author__ and __school__.
2. After that, I did some background research on the __author__ and __school__. I asked the research question of this project and proposed my hypothesis.
3. During data clearning, I found, in the original dataset, a column called __sentence_length__. I believed that this length given by the characters is not informative, so I created a new column storing the number of words in the sentence. Also, I created another column to store the split of the sentence, which is a list of strings. 
4. In EDA, I analyzed the frequency of time and place prepositions in both Modern and Acient Greek philosophy, and plot the relationship in bar plot. Also, I defined two functions __remove_stop_words__ and __remove_low_frequency_words__ to remove the __stop_words__ and the low frequency words, so that I will be able to draw the WordCloud.

### Interpretation of the results in EDA
1. In the EDA, I acquired the frequency of the commonly seen time and place preposition in both Modern and Ancient Greek Philosophy sentences. 
The Result is that: <br>
total words in modern: 2488549 <br>
modern_place_frequency: 270343 <br>
modern_time_frequency: 169267 <br>

    total words in ancient greek: 2274867 <br>
    ancient_place_frequency: 231442 <br>
    ancient_time_frequency: 161901 <br>

    Also the relationship between these two periods of philosophy is plotted in the bar graph in the section of EDA. <br>
    By looking at the data and the plot, I could conclude that there is not much difference in the uses of prepositions during these two periods of time, and the existing difference might be the error. However, we could also observe that the use of place preposition is more than that of the time preposition. There might be two possible explanations. First, the time preposition list contains less words than that of the place preposition. Second, the philosopher indeed tends to use place preposition more than time preposition.

2. After removing the __stop_words__ and the low frequency words, the two __Word Clouds__ could support my hypothesis. <br>
In Modern Philosophy, words philosopher used frequently are "idea", "us", "man", "things", "sense power", "mind", and etc. <br>
In Ancient Greek philosophy, words philosopher used frequently are "man", "part", "things", "must", "animal", "motion", "like", and etc. <br>
Even though there is a few words overlapping, we can still observe that words tend to be close to the reality of the time. For example, ancient people would certainly be concerned about "motion", "animal", "man", because these are what support their livings. In Modern Philosophy, people are being physically satisifed, so philosophers would have more imagination, innovation or idea. As a result, "idea", "us", "mind", and "sense power" are what being used the most in the sentences.

### Conclusion

The __research question__ was how modern philosophy is different from the Ancient Greek Philosophy, from the aspects of writing language and the central theme, and I __hypothesized__ that the writing language would be different because the way people talk and write are evolving. Also, the central themes were also shifted because the ideology and understanding of life are changing in an unpredictable speed. <br>
By the previous parts, I did not prove whether philosophers' writing language or habit are changed. However, by the EDA, I showed how the central themes were shifted based on the reality of time.
"""